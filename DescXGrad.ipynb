{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.use('Qt5Agg')  # Set the backend to a valid option like 'TkAgg'\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# print(os.environ.get('MPLBACKEND'))\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abrirImagenesEscaladas( carpeta, escala=32 ):\n",
    "    # abre todas las imagenes de la carpeta, y las escala de tal forma que midan (escala x escala)px\n",
    "    # devuelve las imagenes aplanadas -> vectores de tamano escala^2 con valores entre 0 y 1\n",
    "    imagenes = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(carpeta):\n",
    "        for file in filenames:\n",
    "            if file.endswith('DS_Store'):\n",
    "                continue\n",
    "            img = Image.open( os.path.join(carpeta, file) )\n",
    "            img = img.resize((escala, escala))\n",
    "            img.convert('1')\n",
    "            img = np.asarray(img)\n",
    "            if len(img.shape)==3:\n",
    "                img = img[:,:,0].reshape((escala**2 )) / 255\n",
    "            else:\n",
    "                img = img.reshape((escala**2 )) / 255\n",
    "            \n",
    "            imagenes.append( img )\n",
    "\n",
    "    return imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "if(True):\n",
    "    img_train_sin_neumonia = abrirImagenesEscaladas('./chest_xray/train/NORMAL/')\n",
    "    img_train_neumonia = abrirImagenesEscaladas('./chest_xray/train/PNEUMONIA/') # NO FUNCIONA :(\n",
    "    img_test_sin_neumonia = abrirImagenesEscaladas('./chest_xray/test/NORMAL/')\n",
    "    img_test_neumonia = abrirImagenesEscaladas('./chest_xray/test/PNEUMONIA/')\n",
    "\n",
    "    data = (img_train_sin_neumonia, img_train_neumonia, img_test_sin_neumonia, img_test_neumonia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizar los parametros de la funcion f para el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancear_datos(imagenes_entrenamiento):\n",
    "\n",
    "    img_train_sin_neumonia = imagenes_entrenamiento[0]\n",
    "    img_train_neumonia =imagenes_entrenamiento[1]\n",
    "    img_test_sin_neumonia =imagenes_entrenamiento[2]\n",
    "    img_test_neumonia = imagenes_entrenamiento[3]\n",
    "\n",
    "    # MAX NUMBER OF IMAGES\n",
    "    n_train = min(len(img_train_sin_neumonia), len(img_train_neumonia))\n",
    "    n_test = min(len(img_test_sin_neumonia), len(img_test_neumonia))\n",
    "\n",
    "    # BALANCE\n",
    "    img_train_sin_neumonia = img_train_sin_neumonia[:n_train]\n",
    "    img_train_neumonia = img_train_neumonia[:n_train]\n",
    "    img_test_sin_neumonia = img_test_sin_neumonia[:n_test]\n",
    "    img_test_neumonia = img_test_neumonia[:n_test]\n",
    "\n",
    "    \n",
    "    return (img_train_sin_neumonia, img_train_neumonia, img_test_sin_neumonia, img_test_neumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = balancear_datos(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sin, train_con, test_sin, test_con = data\n",
    "training_data = (train_sin,train_con)\n",
    "testing_data = (test_sin,test_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Derivadas Parciales\n",
    "\n",
    "Derivada con respecto a $\\mathbf{w}$:\n",
    "\n",
    "$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} = \\sum_{i=1}^{N} \\left( \\left(1 + \\tanh(\\mathbf{w} \\cdot \\mathbf{i} + b)\\right)^2 - d_i \\right) \\left(1 - \\tanh^2(\\mathbf{w} \\cdot \\mathbf{i} + b)\\right) \\mathbf{i}\n",
    "$\n",
    "\n",
    "Derivada con respecto a $b$:\n",
    "\n",
    "$\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=1}^{N} \\left( \\left(1 + \\tanh(\\mathbf{w} \\cdot \\mathbf{i} + b)\\right)^2 - d_i \\right) \\left(1 - \\tanh^2(\\mathbf{w} \\cdot \\mathbf{i} + b)\\right)\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_w(i,w,b,d):\n",
    "    \"\"\"Derivada de L con respecto a W\n",
    "\n",
    "    Args:\n",
    "        i (Vector): imagen reshaped a un vector de tamano 32^2\n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "\n",
    "    Returns:\n",
    "        Vector: Gradiente de la probabilidad con respecto a los pesos\n",
    "    \"\"\"\n",
    "    # t0=tanh(b+W⊤⋅i)\n",
    "    #return: (1−t0^2)⋅((1+t0)/2−d)⋅i\n",
    "    \n",
    "    t0 = np.tanh(np.dot(w,i)+b)\n",
    "    return (1-t0**2)*(((1+t0)/2)-d) * i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_b(i,w,b,d):\n",
    "    \"\"\"Derivada de l con respecto a b \n",
    "\n",
    "    Args:\n",
    "        i (Vector): imagen reshaped a un vector de tamano 32^2\n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "\n",
    "    Returns:\n",
    "        Float: Gradiente de la probabilidad con respecto al bias\n",
    "    \"\"\"\n",
    "    #t0=tanh(b+W⊤⋅i)\n",
    "    #(1−t0^2)⋅((1+t0)/2−d)   \n",
    "    t0 = np.tanh(np.dot(w,i)+b)\n",
    "    return (1-t0**2)*(((1+t0)/2)-d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(i,w,b):\n",
    "    \"\"\"Funcion tanh \n",
    "\n",
    "    Args:\n",
    "        i (Vector): imagen reshaped a un vector de tamano 32^2\n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "\n",
    "    Returns:\n",
    "        probabolidad: 0 < p < 1: Probabilidad de que la imagen sea un 1 (Tiene neumonia)\n",
    "    \"\"\"\n",
    "    tan = np.tanh(np.dot(w,i)+b)\n",
    "    return (tan + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_cuadratico_testing(data,w_res, b_res):\n",
    "    error = 0\n",
    "    len_data = len(data[0]) + len(data[1])     \n",
    "                \n",
    "    # Testing con imágenes sin neumonía\n",
    "    label = 0\n",
    "    for i in data[0]: \n",
    "        error += (F(i,w_res, b_res) - label)**2 \n",
    "\n",
    "    # Testing con imágenes con neumonía\n",
    "    label = 1\n",
    "    for i in data[1]:\n",
    "        error += (F(i,w_res, b_res) - label)**2 \n",
    "    \n",
    "    return error/len_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Implementar el metodo de descenso por gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente(w,b,gradiente_w, gradiente_b, alpha):\n",
    "    \"\"\"Calcula el descenso por gradiente de w y b \n",
    "\n",
    "    Args:\n",
    "        imagenes_entrenamiento (List): Lista de imagenes de tamano 32^2\n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "        alpha (Float): Learning rate\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Pesos y bias actualizados\n",
    "\n",
    "    \"\"\"\n",
    "    [L_w , L_b()]\n",
    "    w = w - alpha * gradiente_w\n",
    "    b = b - alpha * gradiente_b\n",
    "    return w,b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Calcular el error cuadratico durante la optimizacion para el conjunto de entrenamiento y para el conjunto de testing. Generar las visualizaciones correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datos, alpha=0.005, epochs = 5,seed = 42,plot_graph=True):\n",
    "    \"\"\"Metodo de entrenamiento atraves del descanso de gradiente por la funcion tanh\n",
    "\n",
    "    Args:\n",
    "        datos (tuple): Tupla de dos listas, la primera con las imagenes Normales y la segunda con las imagenes con Neumonia \n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "        alpha (Float): Learning rate\n",
    "        epochs (Int): Numero de iteraciones\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Pesos y bias actualizados\n",
    "    \"\"\"\n",
    "        \n",
    "    datos_sin_neumonia = np.array(datos[0])\n",
    "    datos_con_neumonia = np.array(datos[1])\n",
    "\n",
    "    # inicioamos con pesos aleatorios\n",
    "    # set numpy seed\n",
    "    np.random.seed(seed)\n",
    "    w = np.random.randn(datos_sin_neumonia[0].shape[0]) * 0.01\n",
    "    b = np.random.randn(1) * 0.01\n",
    "   \n",
    "    len_data = len(datos_sin_neumonia) + len(datos_con_neumonia)\n",
    "   \n",
    "    errores = []\n",
    "   \n",
    "    \n",
    "    for epoch in range(epochs):  \n",
    "        \n",
    "        error = 0\n",
    "        gradiente_w = np.zeros_like(w)\n",
    "        gradiente_b = 0\n",
    "       \n",
    "            \n",
    "        # Entrenamiento con imágenes sin neumonía\n",
    "        label = 0\n",
    "        for i in datos_sin_neumonia: \n",
    "            gradiente_w += L_w(i,w,b,label)\n",
    "            gradiente_b += L_b(i,w,b,label)\n",
    "            error += (F(i,w,b) - label)**2 # Falta arreglar esto\n",
    "            \n",
    "        # Entrenamiento con imágenes con neumonía\n",
    "        label = 1\n",
    "        for i in datos_con_neumonia:\n",
    "            gradiente_w += L_w(i,w,b,label)\n",
    "            gradiente_b += L_b(i,w,b,label)\n",
    "            error += (F(i,w,b) - label)**2 # Falta arreglar esto\n",
    "        \n",
    "        # Promediar los gradientes acumulados\n",
    "        gradiente_w /= (len_data)\n",
    "        gradiente_b /= (len_data)\n",
    "        \n",
    "        # Actualización de los parámetros\n",
    "        w, b = descenso_gradiente(w, b, gradiente_w, gradiente_b, alpha)\n",
    "        \n",
    "        error_cuadratico = error/len_data\n",
    "        # Almacenar el error cuadrático promedio para visualización\n",
    "        errores.append(error_cuadratico)\n",
    "          \n",
    "        # Decaer la tasa de aprendizaje\n",
    "        alpha *= 0.95\n",
    "        \n",
    "        # Mostrar el error de la epoch actual\n",
    "        print(f\"\\rError Cuadratico: {error_cuadratico}\",end='',)\n",
    "    \n",
    "    if plot_graph:\n",
    "        plt.plot(errores)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Error Cuadrático')\n",
    "        plt.title('Error Cuadrático durante el Entrenamiento')\n",
    "        plt.show()\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(w,b,datos):\n",
    "    \"\"\" Devuelve el porcentaje de de imagenes correctas que clasifico la funcion encontrada\n",
    "    \n",
    "    Args:\n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "        datos (tuple): Tupla de dos listas, la primera con las imagenes Normales y la segunda con las imagenes con Neumonia \n",
    "\n",
    "    Returns:\n",
    "        Float: Accuracy\n",
    "    \"\"\"\n",
    "    datos_sin_neumonia = datos[0]\n",
    "    datos_con_neumonia = datos[1]\n",
    "    correctos = 0\n",
    "    \n",
    "    for i in datos_sin_neumonia:\n",
    "        if F(i,w,b) < 0.5:\n",
    "            correctos += 1\n",
    "            \n",
    "    for i in datos_con_neumonia:\n",
    "        if F(i,w,b) >= 0.5:\n",
    "            correctos += 1\n",
    "            \n",
    "    return correctos/(len(datos_sin_neumonia)+len(datos_con_neumonia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data: nos devuelve el w y b munimo, con alpha 0.05 para probar\n",
    "w_res, b_res = train(\n",
    "    training_data,\n",
    "    alpha=0.05,\n",
    "    epochs = 500,\n",
    "    seed = 42,\n",
    "    plot_graph=True\n",
    "    )\n",
    "\n",
    "print(f\"Procentaje de datos correctos: {test(w_res,b_res,training_data)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data: calculamos el error cuadratico con los w y b resultantes del training\n",
    "error_total = error_cuadratico_testing(testing_data,w_res,b_res)\n",
    "    \n",
    "print(f\"Error cuadratico: {error_total}\")\n",
    "print(f\"Procentaje de datos correctos: {test(w_res,b_res,testing_data)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "Analizar el impacto del parametro α en la convergencia del metodo. Tomar un rango\n",
    "de 5 valores posibles y analizar la convergencia para el conjunto de testing para los distintos valores de α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_convergencia(errores):\n",
    "    if len(errores) < 2:\n",
    "        return 1\n",
    "    return abs(errores[-1] - errores[-2]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_convergencia(datos, alpha,seed,diferencia_minima, plot_graph=True):\n",
    "    \"\"\"Usamos el mismo test de antes pero ahora probamos convergencia \n",
    "\n",
    "    Args:\n",
    "        datos (tuple): Tupla de dos listas, la primera con las imagenes Normales y la segunda con las imagenes con Neumonia \n",
    "        w (Vector): Pesos de la red\n",
    "        b (Float): Bias de la red\n",
    "        alpha (Float): Learning rate\n",
    "        epochs (Int): Numero de iteraciones\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Pesos y bias actualizados\n",
    "    \"\"\"\n",
    "       \n",
    "    datos_sin_neumonia = np.array(datos[0])\n",
    "    datos_con_neumonia = np.array(datos[1])\n",
    "\n",
    "    # inicioamos con pesos aleatorios\n",
    "    # set numpy seed\n",
    "    np.random.seed(seed)\n",
    "    w = np.random.randn(datos_sin_neumonia[0].shape[0]) * 0.01\n",
    "    b = np.random.randn(1) * 0.01\n",
    "   \n",
    "    len_data = len(datos_sin_neumonia) + len(datos_con_neumonia)\n",
    "   \n",
    "    errores = []\n",
    "    contador = 0\n",
    "    \n",
    "    while(True):  \n",
    "        \n",
    "        error = 0\n",
    "        gradiente_w = np.zeros_like(w)\n",
    "        gradiente_b = 0\n",
    "       \n",
    "            \n",
    "        # Entrenamiento con imágenes sin neumonía\n",
    "        label = 0\n",
    "        for i in datos_sin_neumonia: \n",
    "            gradiente_w += L_w(i,w,b,label)\n",
    "            gradiente_b += L_b(i,w,b,label)\n",
    "            error += (F(i,w,b) - label)**2 # Falta arreglar esto\n",
    "            \n",
    "        # Entrenamiento con imágenes con neumonía\n",
    "        label = 1\n",
    "        for i in datos_con_neumonia:\n",
    "            gradiente_w += L_w(i,w,b,label)\n",
    "            gradiente_b += L_b(i,w,b,label)\n",
    "            error += (F(i,w,b) - label)**2 # Falta arreglar esto\n",
    "        \n",
    "        # Promediar los gradientes acumulados\n",
    "        gradiente_w /= (len_data)\n",
    "        gradiente_b /= (len_data)\n",
    "        \n",
    "        # Actualización de los parámetros\n",
    "        w, b = descenso_gradiente(w, b, gradiente_w, gradiente_b, alpha)\n",
    "        \n",
    "        error_cuadratico = error/len_data\n",
    "        \n",
    "        # Almacenar el error cuadrático promedio para visualización\n",
    "        errores.append(error_cuadratico)\n",
    "          \n",
    "        \n",
    "        diferencia = analizar_convergencia(errores)\n",
    "        \n",
    "        # Mostrar el error de la epoch actual\n",
    "        print(f\"\\rError: {errores[-1]}  Diferencia: {diferencia}\",end='',)\n",
    "        \n",
    "        if diferencia < diferencia_minima:\n",
    "            print(f\"\\nConvergio en el epoch: {contador} con aplha: {alpha}\")\n",
    "            break\n",
    "        # Mostrar el error de la epoch actual\n",
    "        # print(f\"\\rError: {errores[-1]}  Diferencia: {np.linalg.norm(gradiente_w)}\",end='',)\n",
    "        \n",
    "       \n",
    "        # if  np.linalg.norm(gradiente_w)  < diferencia_minima:\n",
    "        #     print(f\"\\nConvergio en el epoch: {contador} con aplha: {alpha}\")\n",
    "        #     break\n",
    "        \n",
    "        # Decaer la tasa de aprendizaje\n",
    "        alpha *= 0.95\n",
    "        \n",
    "        contador += 1\n",
    "       \n",
    "        \n",
    "    if plot_graph:\n",
    "        plt.plot(errores)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Error Cuadrático')\n",
    "        plt.title('Error Cuadrático durante el Entrenamiento')\n",
    "        plt.show()\n",
    "\n",
    "    return w,b,contador,alpha,errores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing: Probamos con varios alphas para probar convergencia\n",
    "# alphas = [ 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "# alphas = [ 0.5, 0.25, 0.125, 0.1, 0.05,0.025,0.0125, 0.01]\n",
    "alphas = [0.79, 0.1, 0.122, 0.133, 0.143]\n",
    "# alphas = [ 0.1, 0.111, 0.1195, 0.128, 0.1365, 0.143, 0.154, 0.15675, 0.1595, 0.16225, 0.165]\n",
    "\n",
    "tiempo_ejecucion = []\n",
    "epochs = []\n",
    "alphas_nuevos_valores = []\n",
    "error_cuadratico_training = []\n",
    "porcentaje_correctitud_training = []\n",
    "resultados_w_b = []\n",
    "\n",
    "\n",
    "for i in alphas:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    w_res, b_res, epoch, alpha, error_cuadratico_t = train_test_convergencia(\n",
    "        training_data,\n",
    "        alpha=i,\n",
    "        seed = 42,\n",
    "        diferencia_minima =  1e-7,\n",
    "        plot_graph=False\n",
    "        )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    resultados_w_b.append((w_res,b_res))\n",
    "\n",
    "    tiempo_ejecucion.append(end_time - start_time)\n",
    "    epochs.append(epoch)\n",
    "    alphas_nuevos_valores.append(alpha)\n",
    "    error_cuadratico_training.append(error_cuadratico_t)\n",
    "    porcentaje_correctitud_training.append(test(w_res,b_res,training_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data: calculamos el error cuadratico con los w y b resultantes del training para todos los alphas\n",
    "errores_alphas = []\n",
    "test_efectividad = []\n",
    "\n",
    "for w_res,b_res in resultados_w_b:\n",
    "    error = error_cuadratico_testing(testing_data, w_res,b_res)\n",
    "    errores_alphas.append(error)\n",
    "    test_efectividad.append(test(w_res,b_res,testing_data))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_str = [str(round(alpha,3)) for alpha in alphas]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "#Progresion del alpha segun el punto de inicio\n",
    "plt.plot(alphas_str, alphas_nuevos_valores, marker='o', linestyle='-', color='b')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Valores finales de alpha')\n",
    "plt.title('Progresion del alpha segun el punto de inicio')\n",
    "\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "#Como los valores de alpha influyen al error\n",
    "plt.plot(alphas_str, error_cuadratico_training, marker='o', linestyle='-', color='r')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Error cuadratico')\n",
    "plt.title('Error cuadratico para cada alpha')\n",
    "\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "#Como los valores de alpha influyen al porcentaje de correctitud\n",
    "plt.plot(alphas_str, porcentaje_correctitud_training, marker='o', linestyle='-', color='r')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Correctitud (%)')\n",
    "plt.title('Porcentaje de correctitud para cada alpha')\n",
    "\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "#Tiempos de ejecucion para cada alpha\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.bar(alphas_str, tiempo_ejecucion, color='skyblue')\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Tiempo de ejecucion (segundos)')\n",
    "plt.title('Tiempos de ejecucion para cada alpha')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Cantidad de iteraciones hasta convergencia\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.bar(alphas_str, epochs, color='skyblue')\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Iteraciones')\n",
    "plt.title('Cantidad de iteraciones hasta convergencia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(alphas_str, errores_alphas, marker='o', linestyle='-', color='b')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Errores')\n",
    "plt.title('Calculo de errores para diferentes valores de alpha (en testing)')\n",
    "\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(alphas_str, test_efectividad, marker='o', linestyle='-', color='b')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Valores de aplha')\n",
    "plt.ylabel('Efectividad (%)')\n",
    "plt.title('Efectividad para diferentes valores de alpha (en testing)')\n",
    "\n",
    "plt.grid(True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor valor de alpha es 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "¿Como impacta el tamaño del escalado de las imagenes en la efectividad del metodo? ¿Y en el tiempo de computo?. Realizar los experimentos y graficos acordes para estudiar estas limitaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probar_escalados(esclados):\n",
    "    tiempo_ejecucion_esclado = []\n",
    "    efectividad_training = []\n",
    "    efectividad_testing = []\n",
    "    errors_escalado = []\n",
    "\n",
    "    for i,alpha in esclados:\n",
    "        img_train_sin_neumonia = abrirImagenesEscaladas('./chest_xray/train/NORMAL/',i)\n",
    "        img_train_neumonia = abrirImagenesEscaladas('./chest_xray/train/PNEUMONIA/',i) \n",
    "        img_test_sin_neumonia = abrirImagenesEscaladas('./chest_xray/test/NORMAL/',i)\n",
    "        img_test_neumonia = abrirImagenesEscaladas('./chest_xray/test/PNEUMONIA/',i)\n",
    "\n",
    "        data = (img_train_sin_neumonia, img_train_neumonia, img_test_sin_neumonia, img_test_neumonia)\n",
    "        \n",
    "        data = balancear_datos(data)\n",
    "        \n",
    "        img_train_sin_neumonia, img_train_neumonia, img_test_sin_neumonia, img_test_neumonia= data\n",
    "        training_img_data = (img_train_sin_neumonia, img_train_neumonia)\n",
    "        testing_img_data = (img_test_sin_neumonia, img_test_neumonia)\n",
    "        print(\"Data is imported\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        w_res, b_res, _ , __ = train_test_convergencia(\n",
    "            training_img_data,\n",
    "            alpha=alpha,\n",
    "            seed = 42,\n",
    "            diferencia_minima=1e-10,\n",
    "            plot_graph=False\n",
    "            )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        tiempo_ejecucion_esclado.append(end_time - start_time)\n",
    "        efectividad_training.append(test(w_res,b_res,training_img_data))\n",
    "        \n",
    "        efectividad_testing.append(test(w_res,b_res,testing_img_data))\n",
    "        errors_escalado.append(error_cuadratico_t(testing_img_data,w_res,b_res))\n",
    "    \n",
    "    return tiempo_ejecucion_esclado,efectividad_testing,efectividad_training,errors_escalado\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esclados = [(32,0.05),(64,0.025),(512,0.00125)]\n",
    "tiempo_ejecucion_esclado,efectividad_testing,efectividad_training,errors_escalado = probar_escalados(esclados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### graficos training\n",
    "#Tiempos de ejecucion para cada esclado\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(esclados, tiempo_ejecucion_esclado, marker='o', linestyle='-', color='b', label='Tiempo de ejecucion')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Esclados')\n",
    "plt.ylabel('Tiempo de ejecucion (segundos)')\n",
    "plt.title('Tiempos de ejecucion para cada esclado')\n",
    "plt.legend()  \n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "#Efectividad para el escalado\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(esclados, efectividad_training, marker='o', linestyle='-', color='b', label='Tiempo de ejecucion')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Esclados')\n",
    "plt.ylabel('Efectividad (%)')\n",
    "plt.title('Efectividad de analisis segun diferentes escalados de imagen (Training)')\n",
    "plt.legend()  \n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "#### Graficos testing\n",
    "#errors para el escalado\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(esclados, errors_escalado, marker='o', linestyle='-', color='b', label='Tiempo de ejecucion')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Esclados')\n",
    "plt.ylabel('Error Cuadratico')\n",
    "plt.title('Error cuadratico en testing para cada esclado')\n",
    "plt.legend()  \n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "#Efectividad para el escalado\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(esclados, efectividad_testing, marker='o', linestyle='-', color='b', label='Tiempo de ejecucion')  # Gráfico de líneas\n",
    "\n",
    "plt.xlabel('Esclados')\n",
    "plt.ylabel('Efectividad (%)')\n",
    "plt.title('Efectividad de analisis segun diferentes escalados de imagen (Testing)')\n",
    "plt.legend()  \n",
    "plt.grid(True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 \n",
    "\n",
    "Para el valor de α que tenga mejor valor de convergencia, generar la matriz de confusion y analizar brevemente la efectividad del metodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_de_confusion(datos, w, b):\n",
    "    datos_sin_neumonia = datos[0]\n",
    "    datos_con_neumonia = datos[1]\n",
    "    len_datos = len(datos_sin_neumonia) + len(datos_con_neumonia)\n",
    "    \n",
    "    Verdadero_Positivo = 0\n",
    "    Falso_Negativo = 0\n",
    "    Verdadero_Negativo = 0\n",
    "    Falso_Positivo = 0\n",
    "    \n",
    "    for i in datos_sin_neumonia:\n",
    "        if F(i,w,b) < 0.5:\n",
    "            Verdadero_Negativo += 1\n",
    "        else:\n",
    "            Falso_Positivo += 1\n",
    "            \n",
    "    for i in datos_con_neumonia:\n",
    "        if F(i,w,b) >= 0.5:\n",
    "            Verdadero_Positivo += 1\n",
    "        else:\n",
    "            Falso_Negativo += 1\n",
    "            \n",
    "    matriz = [[Verdadero_Positivo/len_datos , Falso_Negativo/len_datos],\n",
    "              [Verdadero_Negativo/len_datos , Falso_Positivo/len_datos]]\n",
    "    \n",
    "    return matriz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_res, b_res = train(\n",
    "    training_data,\n",
    "    alpha=0.05,\n",
    "    epochs = 500,\n",
    "    seed = 42,\n",
    "    plot_graph=False\n",
    "    )\n",
    "\n",
    "matriz_de_confusion_training = matriz_de_confusion(training_data,w_res, b_res)\n",
    "matriz_de_confusion_testing = matriz_de_confusion(testing_data,w_res, b_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"True Positive  | False positive\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"False Negative | True negative\\n\")\n",
    "\n",
    "print(f\"Training: {matriz_de_confusion_training[:1]}\\n\")\n",
    "print(f\"          {matriz_de_confusion_training[1:]}\\n\")\n",
    "print(f\"Testing: {matriz_de_confusion_testing[:1]}\\n\")\n",
    "print(f\"         {matriz_de_confusion_testing[1:]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "588a077454552c0b608c7a75f739e0012bc0a6317cbb2228f1831255df17ce82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
